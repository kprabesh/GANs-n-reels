{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> GANs &#119070; &nbsp;Reels </h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo ##\n",
    "\n",
    "This notebook showcases our entire process of creating music using a Neural Network. At a high level, there are three main parts to our process of using a GAN to generate music. Namely:\n",
    "1. Encoding: \n",
    "    Converting our dataset of Irish music to a form suitable for the GAN.\n",
    "2. Training: \n",
    "    Feeding the curated data to our customized GAN, and decoding the results.\n",
    "3. Decoding: \n",
    "    Converting the results from our GAN to music "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Encoding ###\n",
    "\n",
    "This process can be broken down to 4 stages:\n",
    "1. Sourcing: Getting the dataset from TheSessions.org/\n",
    "2. Filtering: Pruning data that isn't in our relevant structure \n",
    "3. Cleaning: Using a structured notation to simplify ABC notation\n",
    "4. Vectorizing: Creating vectors out of the cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a365bdbeab92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entire Encoding Process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mraw_to_npy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_abc_to_npy_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Entire Encoding Process\n",
    "%matplotlib inline\n",
    "from src.Generation import raw_to_npy as raw_data\n",
    "raw_data.raw_abc_to_npy_file(update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training ###\n",
    "\n",
    "Our next step is to feed this curated data to our neural network. We opted for a Deconvolutional GAN since they are renowned for performing well on images, and making training a lot more stable. The parameters used were:\n",
    "- Stride: 2\n",
    "- Output function: Sigmoid\n",
    "- Padding: 4 x 4 x 16\n",
    "- Batch Size: 60\n",
    "\n",
    "At a high level, this process consists of:\n",
    "1. Building a Generator and a Discriminator\n",
    "2. Padding and transposing data to suit our GAN\n",
    "3. Checking for mode collapse every fixed number of iterations\n",
    "4. Converting output of the GAN to a Vectorized array\n",
    "\n",
    "Since training a Generative Adversarial Network takes a lot of computing power, we trained ours using Google Colab [found here](https://github.com/vin-nag/GANs-n-reels/blob/master/src/Model/MusicGAN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Generated GAN ####\n",
    "\n",
    "Once we trained our network, we use it to generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "trained_GAN = keras.models.load_model(\"../src/Model/Trained/generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "noise = np.random.normal(0, 1, [1, 100]) #20 arrays of noise of shape [100,]\n",
    "generated_samples = trained_GAN.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples = generated_samples[:,:-1, 4:-4]\n",
    "generated_samples = np.squeeze(generated_samples, axis=3) #Remove colour channel\n",
    "generated_samples = generated_samples.reshape([-1, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PITCH = 80\n",
    "MIN_PITCH = 53\n",
    "MID_PITCH = (MAX_PITCH + MIN_PITCH) / 2\n",
    "RANGE = MAX_PITCH - MIN_PITCH\n",
    "\n",
    "#Map from [-1, 1] to [MIN_PITCH, MAX_PITCH]\n",
    "generated_samples = (RANGE * generated_samples) + MID_PITCH\n",
    "\n",
    "#Make values discrete\n",
    "generated_samples = generated_samples.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decoding ###\n",
    "\n",
    "After the training is done, we decode the resulting vector (provided the GAN didn't collapse) back to music, using essentially the inverse of our encoding process.\n",
    "\n",
    "This consists of:\n",
    "1. Converting Vectors to ABC Notation\n",
    "2. Converting ABC Notation to a format readable by a Music Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Decoding Process\n",
    "# import matplotlib as plt\n",
    "from src.Generation.Vectorizing import Decoding\n",
    "\n",
    "decoder = Decoding.Decoder.from_single_vector(generated_samples, presentation=True)\n",
    "\n",
    "decoder.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An interesting tune generated earlier\n",
    "num = 7\n",
    "\n",
    "generated = Decoding.Decoder.from_single_vector('generated_samples.npy', presentation=True)\n",
    "decoder.play(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
